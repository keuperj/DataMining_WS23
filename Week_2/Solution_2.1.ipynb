{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2.1\n",
    "### Scrape and Analyse\n",
    "\n",
    "* API [https://beautiful-soup-4.readthedocs.io/en/latest/](https://beautiful-soup-4.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "Scrape data from the website [http://www.nationmaster.com](http://www.nationmaster.com/), convert it into Pandas data frames and use pandas queries to answer the following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1\n",
    "Get the number of internet users per country, remove all NaN entries and return the top 10 countries with the highest absolute number of internet users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use request to get data from URL\n",
    "res = requests.get(\"http://www.nationmaster.com/country-info/stats/Media/Internet-users\")\n",
    "#parse data as HTML\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "#extract tables\n",
    "table = soup.find_all('table')[0]\n",
    "#convert table to pandas data frame\n",
    "df = pd.read_html(str(table)) #returns list of dataframes (one for each table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df[0].drop(columns=['GRAPH', 'HISTORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.dropna(subset=['#','COUNTRY','AMOUNT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df0.drop(columns=['#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['AMOUNT'] = df0['AMOUNT'].replace({'million': '*1e6'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df0['AMOUNT'] = df0['AMOUNT'].map(pd.eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0.sort_values(by=['AMOUNT'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2\n",
    "Get the number of internet users per country, remove all NaN entries and return the top 10 countries with the highest number of internet users relative to the populutation. Hint: you need to scrape the population number from another page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use request to get data from URL\n",
    "res = requests.get(\"http://www.nationmaster.com/country-info/stats/People/Population\")\n",
    "#parse data as HTML\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "#extract tables\n",
    "table = soup.find_all('table')[0]\n",
    "#convert table to pandas data frame\n",
    "df_pop_list = pd.read_html(str(table)) #returns list of dataframes (one for each table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = df_pop_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop = df_pop.drop(columns=['GRAPH', 'HISTORY'])\n",
    "df_pop = df_pop.dropna(subset=['#','COUNTRY','AMOUNT'])\n",
    "df_pop = df_pop.drop(columns=['#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pop['AMOUNT'] = df_pop['AMOUNT'].replace({'million': '*1e6','billion': '*1e9'}, regex=True).map(pd.eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df0, df_pop, on=\"COUNTRY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['relative'] = result.apply(lambda x: x['AMOUNT_x'] / x['AMOUNT_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by=['relative'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3\n",
    "Compute the correlation between the crime rate (murders per 100k) and the education level. Compare this to the correlation of crime rate and poverty (relative BIP). Hint: use pandas build in correlation function: [https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use request to get data from URL\n",
    "res = requests.get(\"https://www.nationmaster.com/country-info/stats/Crime/Violent-crime/Murder-rate\")\n",
    "#parse data as HTML\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "#extract tables\n",
    "table = soup.find_all('table')[0]\n",
    "#convert table to pandas data frame\n",
    "df_murder_list = pd.read_html(str(table)) #returns list of dataframes (one for each table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_murder = df_murder_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use request to get data from URL\n",
    "res = requests.get(\"https://www.nationmaster.com/country-info/stats/Education/High-school-enrolment-rate\")\n",
    "#parse data as HTML\n",
    "soup = BeautifulSoup(res.content,'lxml')\n",
    "#extract tables\n",
    "table = soup.find_all('table')[0]\n",
    "#convert table to pandas data frame\n",
    "df_edu_list = pd.read_html(str(table)) #returns list of dataframes (one for each table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edu = df_edu_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_murder = df_murder.drop(columns=['GRAPH', 'HISTORY','DATE'])\n",
    "df_murder = df_murder.dropna(subset=['#','COUNTRY','AMOUNT'])\n",
    "df_murder = df_murder.drop(columns=['#'])\n",
    "\n",
    "df_edu = df_edu.drop(columns=['GRAPH', 'HISTORY','DATE'])\n",
    "df_edu = df_edu.dropna(subset=['#','COUNTRY','AMOUNT'])\n",
    "df_edu = df_edu.drop(columns=['#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_murder = df_murder.rename(columns={\"AMOUNT\": \"murder-100k\"})\n",
    "df_edu = df_edu.rename(columns={\"AMOUNT\": \"highschool-rate\"})\n",
    "\n",
    "df_murder_edu = pd.merge(df_murder, df_edu, on=\"COUNTRY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_murder_edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_murder_edu.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REST API\n",
    "#### Using data from [https://www.energidataservice.dk](https://www.energidataservice.dk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get data from an open energy data service provider\n",
    "url = 'https://www.energidataservice.dk/proxy/api/datastore_search?resource_id=nordpoolmarket&limit=500'\n",
    "\n",
    "response = requests.get(url)\n",
    "dictr = response.json() #parse json to dict\n",
    "recs = dictr['result']['records'] \n",
    "df = json_normalize(recs) #flatten json files into data frame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4\n",
    "Compute overview statistics (mean, variance, quantiles, counts,...) for all variables. Hint: there is a single pandas call to get this ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 \n",
    "Compute the average ***SpotSale*** by each day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['HourUTC'])\n",
    "df['Date'] = df['Date'].dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Date')['SpotSale'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6 \n",
    "Compute the day with the highest variance in ***SpotPurchase***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Date')['SpotPurchase'].var().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
